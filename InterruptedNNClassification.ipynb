{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mne.decoding import CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Extract_data import Extract_data_from_subject\n",
    "from preprocessing import Select_time_window, csp_transform, bandpass_filter\n",
    "from TOL_dataset_utils import Transform_for_classificator\n",
    "from constants import *\n",
    "from models.NN import Net\n",
    "from loops import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_for_participant(module, model_name, results_save, save_dir, Condition, subject, accuracy_list):\n",
    "     if results_save:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        file_name = save_dir + \"_\" + module + \"_\" + model_name + \"_AVG_CV_\" + Condition  + \"_Subject_\" + str(subject)+ \".npy\"\n",
    "\n",
    "        np.save(file_name, accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasifikacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jovan/Fax/Treca_godina/RI/Projekat/Kod/preprocessing.py:27: RuntimeWarning: filter_length (1677) is longer than the signal (508), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  X_filtered = mne.filter.filter_data(X, sample_freq, freq_low, freq_high, n_jobs = n_jobs, verbose = False)\n",
      "/Users/jovan/miniconda3/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0018 (2.2e-16 eps * 768 dim * 1.1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0017 (2.2e-16 eps * 768 dim * 9.7e+09  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0018 (2.2e-16 eps * 768 dim * 1.1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0021 (2.2e-16 eps * 768 dim * 1.2e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0019 (2.2e-16 eps * 768 dim * 1.1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0017 (2.2e-16 eps * 768 dim * 9.8e+09  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0018 (2.2e-16 eps * 768 dim * 1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0021 (2.2e-16 eps * 768 dim * 1.2e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0018 (2.2e-16 eps * 768 dim * 1.1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0017 (2.2e-16 eps * 768 dim * 9.8e+09  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0018 (2.2e-16 eps * 768 dim * 1.1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0021 (2.2e-16 eps * 768 dim * 1.2e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0019 (2.2e-16 eps * 768 dim * 1.1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0016 (2.2e-16 eps * 768 dim * 9.4e+09  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0018 (2.2e-16 eps * 768 dim * 1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0019 (2.2e-16 eps * 768 dim * 1.1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0018 (2.2e-16 eps * 768 dim * 1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0015 (2.2e-16 eps * 768 dim * 9.1e+09  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0018 (2.2e-16 eps * 768 dim * 1e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.0021 (2.2e-16 eps * 768 dim * 1.2e+10  max singular value)\n",
      "    Estimated rank (mag): 768\n",
      "    MAG: rank 768 computed from 768 data channels with 0 projectors\n",
      "Reducing data rank from 768 -> 768\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([64, 4])\n",
      "train loop: torch.Size([32, 4])\n",
      "Subject: 1 NN: Avg accuracy: 0.25 Best accuracy: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jovan/Fax/Treca_godina/RI/Projekat/Kod/preprocessing.py:27: RuntimeWarning: filter_length (1677) is longer than the signal (508), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  X_filtered = mne.filter.filter_data(X, sample_freq, freq_low, freq_high, n_jobs = n_jobs, verbose = False)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# izvlacenje samo covert trial-a za sva 4 pravca\u001b[39;00m\n\u001b[1;32m      7\u001b[0m X, y \u001b[38;5;241m=\u001b[39m Transform_for_classificator(X, y, CONDITIONS, CLASSES)\n\u001b[0;32m----> 9\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mbandpass_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAMPLE_FREQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m outer_cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mN_SPLITS, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m Net()\n",
      "File \u001b[0;32m~/Fax/Treca_godina/RI/Projekat/Kod/preprocessing.py:27\u001b[0m, in \u001b[0;36mbandpass_filter\u001b[0;34m(bands, sample_freq, X, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m freq_low \u001b[38;5;241m=\u001b[39m band[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m freq_high \u001b[38;5;241m=\u001b[39m band[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 27\u001b[0m X_filtered \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_low\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_high\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Stack features\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m band_number \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m<decorator-gen-78>:10\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/mne/filter.py:1112\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n\u001b[1;32m   1097\u001b[0m filt \u001b[38;5;241m=\u001b[39m create_filter(\n\u001b[1;32m   1098\u001b[0m     data,\n\u001b[1;32m   1099\u001b[0m     sfreq,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     fir_design,\n\u001b[1;32m   1110\u001b[0m )\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfir\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1112\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_overlap_add_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     data \u001b[38;5;241m=\u001b[39m _iir_filter(data, filt, picks, n_jobs, copy, phase)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/mne/filter.py:398\u001b[0m, in \u001b[0;36m_overlap_add_filter\u001b[0;34m(x, h, n_fft, phase, picks, n_jobs, copy, pad)\u001b[0m\n\u001b[1;32m    394\u001b[0m         x[p] \u001b[38;5;241m=\u001b[39m _1d_overlap_filter(\n\u001b[1;32m    395\u001b[0m             x[p], \u001b[38;5;28mlen\u001b[39m(h), n_edge, phase, cuda_dict, pad, n_fft\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     data_new \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pp, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(picks):\n\u001b[1;32m    402\u001b[0m         x[p] \u001b[38;5;241m=\u001b[39m data_new[pp]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/mne/parallel.py:128\u001b[0m, in \u001b[0;36mparallel_func.<locals>.run_verbose\u001b[0;34m(verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_verbose\u001b[39m(\u001b[38;5;241m*\u001b[39margs, verbose\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlevel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m use_log_level(verbose\u001b[38;5;241m=\u001b[39mverbose):\n\u001b[0;32m--> 128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/mne/filter.py:411\u001b[0m, in \u001b[0;36m_1d_overlap_filter\u001b[0;34m(x, n_h, n_edge, phase, cuda_dict, pad, n_fft)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;124;03m\"\"\"Do one-dimensional overlap-add FFT FIR filtering.\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# pad to reduce ringing\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m x_ext \u001b[38;5;241m=\u001b[39m \u001b[43m_smart_pad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_edge\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m n_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x_ext)\n\u001b[1;32m    413\u001b[0m x_filtered \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(x_ext)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/mne/cuda.py:374\u001b[0m, in \u001b[0;36m_smart_pad\u001b[0;34m(x, n_pad, pad)\u001b[0m\n\u001b[1;32m    372\u001b[0m n_pad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_pad)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m n_pad\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m2\u001b[39m,)\n\u001b[0;32m--> 374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mn_pad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (n_pad \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/core/_methods.py:64\u001b[0m, in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_all\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for subject in SUBJECT_NUMBERS:\n",
    "\n",
    "    X, y = Extract_data_from_subject(ROOT, subject, DATA_TYPE)\n",
    "    # vreme kada postoji nadrazaj\n",
    "    X = Select_time_window(X, START_T, END_T, SAMPLE_FREQ)\n",
    "    # izvlacenje samo covert trial-a za sva 4 pravca\n",
    "    X, y = Transform_for_classificator(X, y, CONDITIONS, CLASSES)\n",
    "\n",
    "    X = bandpass_filter(bands, SAMPLE_FREQ, X, DEVICE)\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    model = Net()\n",
    "    model.to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR_STEP_SIZE)\n",
    "\n",
    "\n",
    "    # store avg accuracy for each fold\n",
    "    cv_metrics_log = [0 for i in range(N_SPLITS)]\n",
    "\n",
    "    # CV\n",
    "    for i, (train_indices, test_indices) in enumerate(outer_cv.split(X, y)):\n",
    "\n",
    "        # Pretprocesiranje\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        X_train, X_test = csp_transform(X_train, y_train, X_test, csp) # reshapes so scaler is applicable\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Tenzori\n",
    "        X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "        X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "\n",
    "        # Create datasets for cross validation\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        test_dataset = TensorDataset(X_test, y_test)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = False)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size = 64, shuffle = False)\n",
    "\n",
    "        for _ in range(EPOCHS):\n",
    "          train_loop(train_dataloader, model, loss_fn, optimizer, DEVICE)\n",
    "          cv_metrics_log[i] += test_loop(test_dataloader, model, loss_fn, DEVICE)\n",
    "        \n",
    "        # avg accuracy for current fold\n",
    "        cv_metrics_log[i] /= EPOCHS\n",
    "\n",
    "\n",
    "\n",
    "    # end of CV loop\n",
    "    best_accuracy = max(cv_metrics_log)\n",
    "    avg_model_accuracy = sum(cv_metrics_log)/N_SPLITS\n",
    "    print(f'Subject: {subject} NN: Avg accuracy: {avg_model_accuracy} Best accuracy: {best_accuracy}')\n",
    "    save_results_for_participant(\"TORCH\", \"NN\", SAVE, SAVE_DIR, CONDITIONS[0], subject, avg_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
